## 生产实践

## 1. 服务框架, 注册中心, 网关系统

部署几台机器，每台机器的配置是什么，每天整体的流量有多少，高峰期的请求量有多少，你的整体系统是否抗住了? 各个服务之间的超时、重试、幂等，是否搞定了。 生产细节问题，每秒3000并发请求，各个服务部署多少机器，机器的配置，数据库的机器和配置，网关的机器和配置，注册中心的机器和配置，什么样的机器配置能抗多大的流量和请求



### 服务中心

服务上线，注册表多级缓存同步1秒，注册表拉取频率降低为1秒
服务心跳，1秒上报1次
故障发现，1秒钟检查一次1心跳，如果发现2秒内服务没上报心跳，认为故障了

+ 服务注册中心都没任何压力，最多就是每秒钟几十次请求而已
+ 服务注册中部署个2台机器，每台机器就是4核8G，高可用冗余，任何一台机器死掉，不会影响系统的运行
+ 服务注册中心这样的一个处理逻辑，4核8G的机器，每秒钟轻松抗几百请求，上千请求也是可以的

通常来说，如果每秒钟的并发在1000以内的话，很少部署的，每个服务部署2台机器，每台机器4核8G，每台机器每秒抗个几百请求。大部分的系统，高峰期每秒几百请求，低峰期每秒几十请求，甚至几个请求



### 网关服务

网关系统，4核8G的机器，一台机器抗每秒几百请求，部署3~4台机器，保证可以网关系统每台机器的压力比较小，进一步保证网关系统可靠性



### 数据库

数据库，32核64G，最多抗个每秒钟几千请求问题不大，平时抗个每秒钟几十或者几百请求，三四千请求，但是只不过此时会导致MySQL机器的负载很高，CPU使用率很高，磁盘IO负载很高，网络负载很高





## 2. 并发流量

每个服务每天多少请求量，高峰期每秒钟多少请求量，任何一个开源系统都需要对自己运行过程中各种请求量、每秒的请求量、成功次数、失败次数，在内存里直接做一些计数，他会给你开放一些端口号，比如http端口号，你只要请求他这个端口号，他就会把这些metrics统计返回给你

在你负责的核心服务里，核心接口，开发一个简单的metric统计机制，AtomicLong，原子性，并发下数据统计准确，不会错误，每个接口被调用的时候，一个是可以对每个接口每分钟都做一个Metric统计。 对每个接口每天的请求使用一个AtomicLong做一个计数，统计出来每天的请求次数。 计算一下每个接口从请求到执行完毕，需要耗费多长时间，算一下每个接口平均的请求延时，TP99，TP95，TP90，TP50，TP99，99%的请求耗费的时间在100ms以内，但是1%的请求可能耗费的时间在100ms以上

**TP99 = 100ms**
**TP95 = 50ms，95%的请求耗费的时间多在50ms以内，但是5%的请求耗费的时间在50ms以上**

平均响应延时, 可以计算出来这个接口平均响应延时，把每次调用的耗时跟历史总耗时加起来，除以当前的请求次数，不就是最新的接口响应平均延时

**高峰**: 260K, 70mins, 10pods, averg 0.5s



## 3. 服务扩容

访问量扩大10倍，如何扩容

**网关扩容**直接多部署10倍的机器即可，前面的Nginx做会负载均衡，把流量均匀分发给各个网关机器

**注册中心扩容**服务实例变多了10倍，此时几十个服务实例，几百个服务实例，**对eureka机器会造成每秒几百请求**，没问题，eureka机器，8核16G的配置，单机抗上千请求，很轻松

**数据库扩容**，数据库本来是每秒几百请求，10倍，每秒高峰期是三四千请求，横向扩容很麻烦，可以考虑给单个数据库部署的机器提高配置，32核128G高配物理机，每秒钟抗几千请求问题不大



## 4. 超时设置

分布式系统，拆分为很多个服务之后，他们互相之间要进行调用，平时服务内要优化的一些参数其实不多，服务与服务之间的调用，会不会出现调用的超时，每个服务超时的时间是多长，超时之后是否要进行重试，重试几次

### 高可用

+ **hystrix**进行资源隔离、熔断、降级
+ **zuul**网关层直接进行限流



### Ribbon优化

#### 初始化优化

Spring Cloud生产优化，系统第一次启动的时候，人家调用你经常会出现timeout

**每个服务第一次被请求的时候，就去初始化一个Ribbon的组件**，初始化这些组件需要耗费一定的时间，所以很容易会导致。让每个服务启动的时候就直接初始化Ribbon相关的组件，**避免第一次请求的时候初始化耗费时间**。 

```properties
ribbon:
  eager-load:
    enabled: true

zuul:
  ribbon:
    eager-load:
      enabled: true

feign:
  hystrix:
enabled: false
```

订单服务和积分服务、wms服务、库存服务之间的请求都是没问题的，日志全部都打印出来了，不会说第一次请求因为ribbon加载过慢导致请求失败的问题

zuul网关层面去请求订单服务的时候，还是可能会认为自己超时了，网络请求都是比较慢的，因为有很多服务与服务之间的调用，order和另外3个服务一套交互下来，zuul而言感觉耗时太久了，还是会认为是超时的

zuul而言感觉耗时太久了，还是会认为是超时的



#### 超时优化

**中小型的系统，没必要直接开启hystrix，资源隔离、熔断、降级，如果你没有设计好一整套系统高可用的方案**

zuul请求一个订单服务，超过1秒就认为超时了，此时会先重试一下订单服务这台机器，如果还是不行就重试一下订单服务的其他机器

**Ribbon设置连接超时，读取超时和最大重试次数**

```xml
<dependency>
  <groupId>org.springframework.retry</groupId>
  <artifactId>spring-retry</artifactId>
</dependency>
```


```properties
ribbon:
  ConnectTimeout: 3000
  ReadTimeout: 3000
  OkToRetryOnAllOperations: true
  MaxAutoRetries: 1
  MaxAutoRetriesNextServer: 1

hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=10000
```



## 5. 接口幂等性

订单服务 -> 创建订单

+ 库存服务 -> 扣减库存
+ wms服务 -> 通知发货
+ 积分服务 -> 增加积分

订单服务调用库存服务的时候，因为网络抖动，请求超时了，超过了秒钟，此时订单服务会重试，再次调用一下库存服务，发送一模一样的请求过去

比如说，订单服务第一次请求库存服务，库存服务其实是把扣减库存的业务逻辑执行成功了，只不过网络问题，导致响应迟迟没有返回给订单服务，可能在1.2s之后返回了响应给订单服务。

订单服务就认为请求超时了，他就再次发送了一个一模一样的请求给库存服务，库存服务可能会再次对库存进行扣减



### 接口幂等性设计原则

+ 数据库唯一索引
+ 基于Redis实现一套幂等性防重框架



对于插入类的操作，一般都是建议大家要在数据库表中设计一些唯一索引


你如果有一个订单被支付了，此时就要通知wms创建一个对应发货单，也是数据库里的一个表，仓库里的人会看到这个发货单，此时他就会根据发货单的信息从仓库里进行拣货，打包，封装，交给物流公司



### 数据库唯一索引 - create

id order_id 订单金额 发货地址 xxxx

对order_id就可以建立一个唯一索引，你插入发货单的时候，同一个order_id最多只能对应一个发货单，不可能说同样的一个order_id对应了多个发货单


订单服务 -> wms服务，出现了重试，导致第二次请求再次让人家创建这个订单的发货单，create语句，order_id触发了唯一索引约束



### 基于Redis实现的防重框架 - update

扣减库存、累加积分，更新，很难通过数据库唯一索引来保证

做一个类似spring mvc里的拦截器这样的东西，在这个拦截器里会拦截所有的请求，对所有的请求都会提取请求对应的参数，GET请求、POST请求、PUT请求，有些参数是跟在URL地址里的，?xx=xx&xx=xx, POST、PUT，可能是请求体里的，可能是一个JSON格式

**把参数拼接在一起，作为key去redis中判断一下，是否存在这个key**，之前附加这些参数的请求是否发起过，如果没有的话，此时就可以把这些参数+接口名称，作为一个key，存储到redis中去

然后呢，把请求放行，去执行这个请求。如果说人家重试再次发起一个这个请求，此时就可以判断出来，参数组成的key在redis中已经存在了，此时就不让执行这个请求了，认为是重复调用了

考虑很多问题，幂等不幂等，通用框架，需要一个公司所有的接口都按照指定的参数来传递，还有很多业务语义的问题

第一次发起一个请求，直接把请求key放入redis，但是他执行的过程中失败了，而且还阻塞了一段时间，此时人家再次重试发起第二次请求，这个时候按照上述的框架逻辑，就会把请求拦截下来了

**中大型互联网公司里也没做一个统一的防重幂等框架，其实一般都是各个服务对自己核心的接口，如果要保证幂等性的话，每个服务根据自己的业务逻辑来实现，而且仅仅是对少数核心接口做幂等性保障**

核心接口，库存服务，扣减库存接口

**比如第一次请求超时1s，1.3s才执行成功，1s以后直接重试，第二次请求成功**

定制化的去针对接口开发幂等性的机制，比如说一旦库存扣减成功之后，就立马要写一条数据到redis里去，order_id_11356_stock_deduct，写入redis中，如果写入成功，就说明之前这个订单的库存扣减，没人执行过

但是如果此时有一些重试的请求过来了，调用了你的库存扣减接口，他同时也进行了库存的扣减，但是他用同样的一个key，order_id_11356_stock_deduct，写入redis中，此时会发现已经有人写过key，key已经存在了

**此时就应该直接对刚才的库存扣减逻辑做一个反向的回滚逻辑**，update product_stock set stock = stock - 100，update product_stock set stock = stock + 100，反向逻辑，回滚掉，自己避免说重复扣减库存


**核心接口，幂等性都是自己保证的**，可能会重试调用你的接口，对于create类的操作，用唯一索引来保证；对update类的操作，建议在核心接口里基于自己的业务逻辑，配合上redis，来保证幂等性


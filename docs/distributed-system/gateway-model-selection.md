# 服务网关

## 1. 技术选型

### 网关的核心功能

+ 动态路由：新开发某个服务，动态把请求路径和服务的映射关系热加载到网关里去；服务增减机器，网关自动热感知
+ 灰度发布
+ 授权认证
+ 性能监控：每个API接口的耗时、成功率、QPS
+ 系统日志
+ 数据缓存
+ 限流熔断



### 现有技术

#### Kong

依托于Nginx实现，OpenResty，lua实现的模块，现成的一些插件，可以直接使用



#### Zuul

Spring Cloud微服务技术架构，基于Java开发，核心网关功能都比较简单，但是比如灰度发布、限流、动态路由之类的，很多都要自己做二次开发, 高并发能力不强，部署到一些机器上去，还要基于Tomcat来部署



#### Nginx+Lua

基于lua自己写类似Kong的网关, Nginx抗高并发的能力很强，少数几台机器部署一下，就可以抗很高的并发，精通Nginx源码，很难，c语言，很难说从Nginx内核层面去做一些二次开发和源码定制



#### 自研网关

自己来写类似Zuul的网关，基于Servlet、Netty来做网关，实现上述所有的功能



## 2. 高并发

![高性能网关Zuul](/Users/daiyu/dev/idea/architect/Java-Interview-Advanced/docs/distributed-system/images/gateway-high-concurrency.png)**LVS + Nginx + Zuul**

网关部署的机器，8核16G QPS 1000+， 每秒是1万请求，5 * 8核16G的机器部署Zuul网关



## 3. 灰度发布实践

开发了一个新的服务，线上部署，配合网关动态路由的功能，在网关里配置一下路径和新服务的映射关系，此时请求过来直接就可以走到新的服务里去

对已有服务进行迭代和开发，新版本，灰度发布，新版本部署少数几台机器，通过一个界面，开启这个服务的灰度发布，**此时zuul filter启用，按照你的规则，把少量的流量打入到新版本部署的机器上去**

观察一下少量流量在新版本的机器上运行是否正常, 版本改成current，全量机器部署，关闭灰度发布功能，网关就会把流量均匀分发给那个服务了



